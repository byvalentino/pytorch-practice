{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runTests(test_class):\n",
    "    unittest.TextTestRunner().run(\n",
    "        unittest.TestLoader().loadTestsFromModule(\n",
    "            test_class()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB = {\n",
    "    \"__pad__\": 0,\n",
    "    \"__bos__\": 1,\n",
    "    \"__eos__\": 2,\n",
    "    \"__unk__\": 3,\n",
    "    \"dog\": 4,\n",
    "    \"cat\": 5,\n",
    "    \"puppy\": 6\n",
    "}\n",
    "\n",
    "CHAR_VOCAB = {\n",
    "    \"__c_pad__\": 0,\n",
    "    \"__bot__\": 1,\n",
    "    \"__eot__\": 2,\n",
    "    \"__c_unk__\": 3,\n",
    "    \"__pad__\": 4,\n",
    "    \"__bos__\": 5,\n",
    "    \"__eos__\": 6,\n",
    "    \"a\": 7,\n",
    "    \"c\": 8,\n",
    "    \"d\": 9,\n",
    "    \"g\": 10,\n",
    "    \"o\": 11,\n",
    "    \"p\": 12,\n",
    "    \"t\": 13,\n",
    "    \"u\": 14,\n",
    "    \"y\": 15\n",
    "}\n",
    "\n",
    "TAG_VOCAB = {\n",
    "    \"__pad__\": 0,\n",
    "    \"__bos__\": 1,\n",
    "    \"__eos__\": 2,\n",
    "    \"animal_class\": 3,\n",
    "    \"offspring\": 4\n",
    "}\n",
    "\n",
    "maxlen=10\n",
    "max_tokenlen=15\n",
    "\n",
    "def seq2idx(items, vocab, begin=\"__bos__\", end=\"__eos__\"):\n",
    "    seq = (\n",
    "        tuple([vocab[begin]]) \n",
    "        + tuple([\n",
    "            vocab[item]\n",
    "            for item in items\n",
    "        ]) \n",
    "        + tuple([vocab[end]]))\n",
    "    #print(seq)\n",
    "    return seq\n",
    "    \n",
    "def padded_seq(seq, maxlen, pad_value):\n",
    "    seqlen = min(maxlen, len(seq))\n",
    "    seq = tuple(seq[:seqlen]) + tuple([pad_value]*(maxlen - seqlen))\n",
    "    return seq, seqlen\n",
    "\n",
    "def get_chars_seq(sentence, char_vocab):\n",
    "    char_seq = tuple([[\"__bos__\"]]) + tuple([\n",
    "        tuple(w) for w in sentence\n",
    "    ]) + tuple([[\"__eos__\"]])\n",
    "    char_seq = tuple([\n",
    "        padded_seq(\n",
    "            seq2idx(\n",
    "                chars,\n",
    "                char_vocab,\n",
    "                begin=\"__bot__\",\n",
    "                end=\"__eot__\"\n",
    "            ),\n",
    "            max_tokenlen,\n",
    "            char_vocab[\"__c_pad__\"]\n",
    "        )[0]\n",
    "        for chars in char_seq\n",
    "    ])\n",
    "    padded_char_value = padded_seq(\n",
    "        seq2idx(\n",
    "            [\"__pad__\"],\n",
    "            char_vocab,\n",
    "            begin=\"__bot__\",\n",
    "            end=\"__eot__\"\n",
    "        ),\n",
    "        max_tokenlen,\n",
    "        char_vocab[\"__c_pad__\"]\n",
    "    )[0]\n",
    "    \n",
    "    return char_seq, padded_char_value\n",
    "    \n",
    "\n",
    "def transform(sentence_tags_item, vocab, char_vocab, tag_vocab):\n",
    "    sentence, tags = sentence_tags_item\n",
    "    word_tensor, word_len = padded_seq(\n",
    "        seq2idx(sentence, VOCAB),\n",
    "        maxlen,\n",
    "        vocab[\"__pad__\"]\n",
    "    )\n",
    "    tag_tensor, tags_len = padded_seq(\n",
    "        seq2idx(tags, TAG_VOCAB),\n",
    "        maxlen,\n",
    "        tag_vocab[\"__pad__\"]\n",
    "    )\n",
    "    assert word_len == tags_len, (\n",
    "        \"Mismatch between padded word seq [{}]\"\n",
    "        \" and padded tag seq [{}]\"\n",
    "    ).format(word_len, tags_len)\n",
    "    \n",
    "    \n",
    "    char_seq, padded_char_value = get_chars_seq(sentence, char_vocab)\n",
    "    char_tensor, char_word_len = padded_seq(char_seq, maxlen, padded_char_value)\n",
    "    assert word_len == char_word_len, (\n",
    "        \"Mismatch between padded word seq [{}]\"\n",
    "        \" and padded char based seq [{}]\"\n",
    "    ).format(word_len, char_word_len)\n",
    "    \n",
    "    seq_len = word_len\n",
    "    \n",
    "    return word_tensor, char_tensor, tag_tensor, seq_len\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10,), (10, 15), (10,), 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_seq, padded_char_value = get_chars_seq([\"dog\", \"cat\", \"dog\", \"puppy\"], CHAR_VOCAB)\n",
    "char_tensor, char_word_len = padded_seq(char_seq, maxlen, padded_char_value)\n",
    "\n",
    "\n",
    "word_tensor, char_tensor, tag_tensor, seq_len = transform((\n",
    "    [\"dog\", \"cat\", \"dog\", \"puppy\"],\n",
    "    [\"animal_class\", \"animal_class\", \"animal_class\", \"offspring\"]\n",
    "), VOCAB, CHAR_VOCAB, TAG_VOCAB)\n",
    "\n",
    "np.array(word_tensor).shape, np.array(char_tensor).shape, np.array(tag_tensor).shape, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTransforms(unittest.TestCase):\n",
    "    def test_seq2idx(self):\n",
    "        self.assertEqual(\n",
    "            seq2idx([\"dog\", \"cat\", \"dog\", \"puppy\"], VOCAB),\n",
    "            (1, 4, 5, 4, 6, 2)\n",
    "        )\n",
    "    \n",
    "    def test_padded_seq(self):\n",
    "        self.assertEqual(\n",
    "            padded_seq(\n",
    "                seq2idx(\n",
    "                    [\"dog\", \"cat\", \"dog\", \"puppy\"],\n",
    "                    VOCAB\n",
    "                ),\n",
    "                maxlen,\n",
    "                VOCAB[\"__pad__\"]\n",
    "            ),\n",
    "            ((1, 4, 5, 4, 6, 2, 0, 0, 0, 0), 6)\n",
    "        )\n",
    "        \n",
    "    def test_padded_char_seq(self):\n",
    "        char_seq, padded_char_value = get_chars_seq([\"dog\", \"cat\", \"dog\", \"puppy\"], CHAR_VOCAB)\n",
    "        char_tensor, char_word_len = padded_seq(char_seq, maxlen, padded_char_value)\n",
    "        self.assertEqual(\n",
    "            np.array(char_tensor).shape,\n",
    "            (maxlen, max_tokenlen)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def test_transform(self):\n",
    "        word_tensor, char_tensor, tag_tensor, seq_len = transform(\n",
    "            (\n",
    "                [\"dog\", \"cat\", \"dog\", \"puppy\"],\n",
    "                [\"animal_class\", \"animal_class\", \"animal_class\", \"offspring\"]\n",
    "            ),\n",
    "            VOCAB,\n",
    "            CHAR_VOCAB,\n",
    "            TAG_VOCAB\n",
    "        )\n",
    "\n",
    "        self.assertEqual(\n",
    "            (\n",
    "                np.array(word_tensor).shape,\n",
    "                np.array(char_tensor).shape,\n",
    "                np.array(tag_tensor).shape,\n",
    "                seq_len\n",
    "            ), ((10,), (10, 15), (10,), 6)\n",
    "        )\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "runTests(TestTransforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentenceDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sentence_tags_items,\n",
    "        transform,\n",
    "        vocab,\n",
    "        char_vocab,\n",
    "        tag_vocab\n",
    "    ):\n",
    "        self.sentence_tags_items = sentence_tags_items\n",
    "        self.transform = transform\n",
    "        self.vocab = vocab\n",
    "        self.char_vocab = char_vocab\n",
    "        self.tag_vocab = tag_vocab\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        word_tensor, char_tensor, tag_tensor, seq_len = self.transform(\n",
    "            self.sentence_tags_items[idx],\n",
    "            self.vocab,\n",
    "            self.char_vocab,\n",
    "            self.tag_vocab\n",
    "        )\n",
    "        \n",
    "        word_tensor = torch.from_numpy(np.asarray(word_tensor))#.view(-1, 1)\n",
    "        char_tensor = torch.from_numpy(np.asarray(char_tensor))\n",
    "        tag_tensor = torch.from_numpy(np.asarray(tag_tensor))#.view(-1, 1)\n",
    "        seq_len = torch.from_numpy(np.asarray([seq_len]))\n",
    "        \n",
    "        return word_tensor, char_tensor, tag_tensor, seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentence_tags_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_tag_items = [\n",
    "    (\n",
    "            [\"dog\", \"cat\", \"dog\", \"puppy\"],\n",
    "            [\"animal_class\", \"animal_class\", \"animal_class\", \"offspring\"]\n",
    "    ),\n",
    "    (\n",
    "            [\"dog\", \"cat\", \"cat\", \"puppy\"],\n",
    "            [\"animal_class\", \"animal_class\", \"animal_class\", \"offspring\"]\n",
    "    ),\n",
    "    (\n",
    "            [\"dog\", \"puppy\", \"dog\", \"puppy\"],\n",
    "            [\"animal_class\", \"offspring\", \"animal_class\", \"offspring\"]\n",
    "    ),\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_dataset = SentenceDataset(\n",
    "    sentence_tag_items,\n",
    "    transform,\n",
    "    VOCAB,\n",
    "    CHAR_VOCAB,\n",
    "    TAG_VOCAB\n",
    ")\n",
    "train_loader = DataLoader(sent_dataset, batch_size=10, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 10]),\n",
       " torch.Size([3, 10, 15]),\n",
       " torch.Size([3, 10]),\n",
       " torch.Size([3, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tensors, char_tensors, tag_tensors, seq_len = next(iter(train_loader))\n",
    "word_tensors.size(), char_tensors.size(), tag_tensors.size(), seq_len.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1d = torch.nn.Conv1d(5, 10, 1, dilation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2,5,4).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d(Variable(torch.rand(2,5,4), requires_grad=False)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = torch.nn.Embedding(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = emb(Variable(torch.LongTensor([[1,2,4,5],[4,3,2,9]]), requires_grad=False))\n",
    "embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.permute(0, 2, 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  0.3917  0.8784  0.5268  0.4315\n",
       " -0.1406  0.2500  1.4438  0.0828\n",
       "  0.1396 -0.2760 -0.3761  0.1704\n",
       " -0.3965 -0.4440  0.2955 -0.3060\n",
       "  0.2451 -0.4238  0.3279  0.2239\n",
       " -0.5347 -1.1390  1.0406 -0.3362\n",
       "  0.0030 -0.7008  0.5324  0.1248\n",
       " -0.1148  0.7700 -0.3185 -0.1458\n",
       " -0.3496 -0.2052 -0.5736 -0.2478\n",
       " -0.1141  0.1016 -0.8129 -0.2597\n",
       "\n",
       "(1 ,.,.) = \n",
       "  0.5268  0.8617  0.8784  0.6424\n",
       "  1.4438 -0.5622  0.2500  1.4265\n",
       " -0.3761 -0.3985 -0.2760 -0.2698\n",
       "  0.2955 -0.7914 -0.4440  0.2630\n",
       "  0.3279  1.0187 -0.4238 -0.3041\n",
       "  1.0406 -0.9597 -1.1390  0.2380\n",
       "  0.5324  0.4073 -0.7008 -0.1318\n",
       " -0.3185  0.5722  0.7700  0.3617\n",
       " -0.5736 -0.5782 -0.2052  0.4115\n",
       " -0.8129 -0.2299  0.1016 -0.6984\n",
       "[torch.FloatTensor of size 2x10x4]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d(embeddings.permute(0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d(embeddings.permute(0, 2, 1)).max(2)[1].size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.unsqueeze(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 15])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_tensors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 15])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_tensors.view(-1, 15).view(3, 10, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CharCNN, self).__init__()\n",
    "        self.char_embedding=4\n",
    "        self.char_conv_features=5\n",
    "        self.char_conv_kernel=1\n",
    "        \n",
    "        self.char_emb = torch.nn.Embedding(\n",
    "            len(CHAR_VOCAB),\n",
    "            self.char_embedding\n",
    "        )\n",
    "        \n",
    "        self.char_conv1d = torch.nn.Conv1d(\n",
    "            self.char_embedding,\n",
    "            self.char_conv_features,\n",
    "            self.char_conv_kernel\n",
    "        )\n",
    "        \n",
    "        self.output_size = self.char_conv_features\n",
    "        \n",
    "    def forward(self, char_tensors):\n",
    "        batch_size, seqlen, char_seqlen = char_tensors.size()\n",
    "        char_tensors = char_tensors.view(-1, char_seqlen)\n",
    "        char_tensors = self.char_emb(char_tensors)\n",
    "        char_tensors = char_tensors.permute(0, 2, 1)\n",
    "        char_tensors = self.char_conv1d(char_tensors)\n",
    "        char_tensors = char_tensors.max(2)[0] # Get the global max\n",
    "        char_tensors = char_tensors.view(batch_size, seqlen, -1)\n",
    "        return char_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 15])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_model = CharCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 15])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_tensors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_model(Variable(char_tensors, requires_grad=False)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 30])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((char_tensors, char_tensors), -1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  0.8364 -0.1794  2.4606  0.3041 -0.3007\n",
       "  2.0133  1.1859  0.9896  1.6575  1.4240\n",
       " -0.3331  1.1859  2.4606  1.6575  1.4240\n",
       "  0.7453  0.0274  0.7354  0.1239  1.8854\n",
       " [torch.FloatTensor of size 4x5], Variable containing:\n",
       "  0  0  1  0  1\n",
       "  1  0  1  0  0\n",
       "  1  1  0  1  1\n",
       "  0  1  1  0  1\n",
       " [torch.LongTensor of size 4x5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.max(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordEmbeddings(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        char_model,\n",
    "    ):\n",
    "        super(WordEmbeddings, self).__init__()\n",
    "        self.char_model = char_model\n",
    "        self.word_embedding = 10\n",
    "        self.word_emb = torch.nn.Embedding(\n",
    "            len(VOCAB),\n",
    "            self.word_embedding\n",
    "        )\n",
    "        \n",
    "        self.output_size = (\n",
    "            self.word_embedding\n",
    "            + self.char_model.output_size\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, word_tensors, char_tensors):\n",
    "        char_based_embs = self.char_model(char_tensors)\n",
    "        #print(char_based_embs.size(), type(char_based_embs.data))\n",
    "        word_embs = self.word_emb(word_tensors)\n",
    "        #print(word_embs.size(), type(word_embs.data))\n",
    "        word_embs = torch.cat(\n",
    "            [word_embs, char_based_embs],\n",
    "            -1\n",
    "        ) # Concat word and char based embeddings\n",
    "        return word_embs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_model = WordEmbeddings(char_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 10]), torch.Size([3, 10, 15]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tensors.size(), char_tensors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 15])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model(\n",
    "    Variable(word_tensors, requires_grad=False),\n",
    "    Variable(char_tensors, requires_grad=False)\n",
    ").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID CNN model\n",
    "\n",
    "https://arxiv.org/pdf/1702.02098.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID_CNN(torch.nn.Module):\n",
    "    \"\"\"ID CNN Encoder\n",
    "    \n",
    "    Input: (batch, input_dims, seqlen)\n",
    "    Outpus: (batch, input_dims, seqlen)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dims,\n",
    "        dialation_block_depth=5,\n",
    "        field_of_view=2,\n",
    "        block_stacks=2\n",
    "    ):\n",
    "        super(ID_CNN, self).__init__()\n",
    "        \n",
    "        # We want to make the input emb same as output emb\n",
    "        # This allows us to recursively stack the layers. \n",
    "        \n",
    "        \n",
    "        self.conv_features = input_dims\n",
    "        self.conv_kernel = 3\n",
    "        self.block_stacks = block_stacks\n",
    "        \n",
    "        self.word_char_conv1d = torch.nn.Sequential(\n",
    "            *[\n",
    "                torch.nn.Sequential(\n",
    "                    torch.nn.Conv1d(\n",
    "                        input_dims,\n",
    "                        self.conv_features,\n",
    "                        kernel_size=self.conv_kernel,\n",
    "                        padding=field_of_view**i,\n",
    "                        dilation=field_of_view**i\n",
    "                    ),\n",
    "                    torch.nn.ReLU()\n",
    "                )\n",
    "                for i in range(dialation_block_depth)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    def forward(self, seq_scores):\n",
    "        for block_idx in range(self.block_stacks):\n",
    "            seq_scores = self.word_char_conv1d(seq_scores)\n",
    "        return seq_scores\n",
    "        \n",
    "        \n",
    "class IDCNNEncoder(torch.nn.Module):\n",
    "    \"\"\"IDCNNEncoder - Encodes word and char based sentence\n",
    "    \n",
    "    Input: \n",
    "        word_tensors - (batch, seqlen), \n",
    "        char_tensors - (batch, seqlen, char_seqlen)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        word_model,\n",
    "    ):\n",
    "        super(IDCNNEncoder, self).__init__()\n",
    "        self.word_model = word_model\n",
    "        self.id_cnn = ID_CNN(self.word_model.output_size)\n",
    "        \n",
    "    def forward(self, word_tensors, char_tensors):\n",
    "        word_embs = self.word_model(word_tensors, char_tensors)\n",
    "        word_embs = word_embs.permute(0, 2, 1)\n",
    "        seq_scores = self.id_cnn(word_embs)\n",
    "        return seq_scores\n",
    "    \n",
    "class IDCNNDecoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dims,\n",
    "        num_classes,\n",
    "        decoder_layers=3\n",
    "    ):\n",
    "        super(IDCNNDecoder, self).__init__()\n",
    "        self.input_dims = input_dims\n",
    "        self.num_classes = num_classes\n",
    "        self.decoder_layers = decoder_layers\n",
    "        self.transform_layer = torch.nn.Sequential(\n",
    "                torch.nn.Linear(self.input_dims, self.num_classes),\n",
    "                torch.nn.ReLU()\n",
    "            )\n",
    "        self.create_decoder_layers()\n",
    "        \n",
    "    def create_decoder_layers(self):\n",
    "        self.id_cnn = torch.nn.ModuleList(\n",
    "            [\n",
    "                ID_CNN(self.num_classes, self.num_classes, block_stacks=1)\n",
    "                for i in range(self.decoder_layers)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    def forward(self, seq_scores):\n",
    "        outputs = []\n",
    "        batch, input_dims, seqlen = seq_scores.size()\n",
    "        seq_scores = seq_scores.permute(0, 2, 1).contiguous()\n",
    "        seq_scores = seq_scores.view(batch*seqlen, input_dims)\n",
    "        seq_scores = self.transform_layer(seq_scores)\n",
    "        seq_scores = seq_scores.view(batch, seqlen, self.num_classes)\n",
    "        seq_scores = seq_scores.permute(0, 2, 1)\n",
    "        for id_cnn in self.id_cnn:\n",
    "            seq_scores = id_cnn(seq_scores)\n",
    "            outputs.append(seq_scores)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 10]), torch.Size([3, 10, 15]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_cnn = IDCNNEncoder(word_model)\n",
    "word_tensors.size(), char_tensors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 15, 10])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_cnn(\n",
    "    Variable(word_tensors, requires_grad=False),\n",
    "    Variable(char_tensors, requires_grad=False)\n",
    ").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cnn_decoder = IDCNNDecoder(15, len(TAG_VOCAB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([3, 5, 10]), torch.Size([3, 5, 10]), torch.Size([3, 5, 10])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs = id_cnn_decoder(id_cnn(\n",
    "    Variable(word_tensors, requires_grad=False),\n",
    "    Variable(char_tensors, requires_grad=False)\n",
    "))\n",
    "[output.size() for output in decoder_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(decoder_outputs, target, loss_fn):\n",
    "    batch, seqlen = target.size()[:2]\n",
    "    #target = target.unsqueeze(2).permute(0,2,1).contiguous().view(-1, 1).squeeze()\n",
    "    target = target.view(-1)\n",
    "    #print(target.size())\n",
    "    loss = None\n",
    "    for output in decoder_outputs:\n",
    "        output = output.permute(0,2,1).contiguous().view(-1, output.size()[1])\n",
    "        #print(output.size())\n",
    "        if loss is None:\n",
    "            loss = loss_fn(output, target)\n",
    "        else: \n",
    "            loss += loss_fn(output, target)\n",
    "    return loss\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs[0].permute(0,2,1).contiguous().view(-1, decoder_outputs[0].size()[1]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 4.7655\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_loss(decoder_outputs, Variable(tag_tensors, requires_grad=False), loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(encoder, decoder, dataloader, num_epochs, history=None):\n",
    "    if history is None:\n",
    "        history = []\n",
    "    cuda = torch.cuda.is_available()\n",
    "    if cuda:\n",
    "        encoder.cuda()\n",
    "        decoder.cuda()\n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()))\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "    for i in range(num_epochs):\n",
    "        per_epoch_losses = []\n",
    "        for batch in dataloader:\n",
    "            word_tensors = Variable(batch[0], requires_grad=False)\n",
    "            char_tensors = Variable(batch[1], requires_grad=False)\n",
    "            tag_tensors = Variable(batch[2], requires_grad=False)\n",
    "            seq_len = Variable(batch[3], requires_grad=False)\n",
    "            if cuda:\n",
    "                word_tensors = word_tensors.cuda()\n",
    "                char_tensors = char_tensors.cuda()\n",
    "                tag_tensors = tag_tensors.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            encoding = encoder(word_tensors, char_tensors)\n",
    "            outputs = decoder(encoding)\n",
    "            loss = get_loss(outputs, tag_tensors, loss_fn)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            per_epoch_losses.append(loss.data[0])\n",
    "        history.append(np.mean(per_epoch_losses))\n",
    "        print('epoch[%d] loss: %.4f' % (i, loss.data[0]))\n",
    "    return history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_model = CharCNN()\n",
    "word_model = WordEmbeddings(char_model)\n",
    "id_cnn = IDCNNEncoder(word_model)\n",
    "id_cnn_decoder = IDCNNDecoder(15, len(TAG_VOCAB))\n",
    "history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0] loss: 4.8157\n",
      "epoch[1] loss: 4.8139\n",
      "epoch[2] loss: 4.8121\n",
      "epoch[3] loss: 4.8102\n",
      "epoch[4] loss: 4.8084\n",
      "epoch[5] loss: 4.8066\n",
      "epoch[6] loss: 4.8048\n",
      "epoch[7] loss: 4.8030\n",
      "epoch[8] loss: 4.8011\n",
      "epoch[9] loss: 4.7993\n"
     ]
    }
   ],
   "source": [
    "history = train(id_cnn, id_cnn_decoder, train_loader, 10, history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {
    "height": "156px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
